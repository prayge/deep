{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tamxYK66Baql"
      },
      "outputs": [],
      "source": [
        "!python -c \"import monai\" || pip install -q \"monai-weekly[gdown, nibabel, tqdm, ignite]\"\n",
        "!python -c \"import matplotlib\" || pip install -q matplotlib\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ddIgk1ABXWz",
        "outputId": "9dc43332-633f-4650-bd0a-924e8bfc86d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MONAI version: 0.9.dev2224\n",
            "Numpy version: 1.21.6\n",
            "Pytorch version: 1.11.0+cu113\n",
            "MONAI flags: HAS_EXT = False, USE_COMPILED = False\n",
            "MONAI rev id: cb6ecb1a22042d4a559b864e74c64d99352dcf7c\n",
            "MONAI __file__: /usr/local/lib/python3.7/dist-packages/monai/__init__.py\n",
            "\n",
            "Optional dependencies:\n",
            "Pytorch Ignite version: 0.4.8\n",
            "Nibabel version: 3.0.2\n",
            "scikit-image version: 0.18.3\n",
            "Pillow version: 7.1.2\n",
            "Tensorboard version: 2.8.0\n",
            "gdown version: 4.4.0\n",
            "TorchVision version: 0.12.0+cu113\n",
            "tqdm version: 4.64.0\n",
            "lmdb version: 0.99\n",
            "psutil version: 5.4.8\n",
            "pandas version: 1.3.5\n",
            "einops version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "mlflow version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "pynrrd version: NOT INSTALLED or UNKNOWN VERSION.\n",
            "\n",
            "For details about installing the optional dependencies, please visit:\n",
            "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AsDiscreted,\n",
        "    EnsureChannelFirstd,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    SaveImaged,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    Resized,\n",
        "    EnsureTyped,\n",
        "    EnsureType,\n",
        "    RandZoomd,\n",
        "    Invertd,\n",
        "    SpatialPadd,\n",
        "    RandAffined\n",
        ")\n",
        "from monai.handlers.utils import from_engine\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset, decollate_batch\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import json\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "print_config()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0w4WDbBBXW1",
        "outputId": "b77cb4fe-3449-4f2e-eba4-549491397880"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "task\n"
          ]
        }
      ],
      "source": [
        "directory = 'task'\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)\n",
        "task = 'Task04_Hippocampus'\n",
        "taskNumber = task[4:6]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_determinism(seed=0)"
      ],
      "metadata": {
        "id": "BbYSg8-DlIVc"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "oe9MrToOKkF7"
      },
      "outputs": [],
      "source": [
        "resource = {\n",
        "    \"Task01_BrainTumour\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task01_BrainTumour.tar\",\n",
        "    \"Task02_Heart\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task02_Heart.tar\",\n",
        "    \"Task03_Liver\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task03_Liver.tar\",\n",
        "    \"Task04_Hippocampus\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task04_Hippocampus.tar\",\n",
        "    \"Task05_Prostate\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task05_Prostate.tar\",\n",
        "    \"Task06_Lung\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task06_Lung.tar\",\n",
        "    \"Task07_Pancreas\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task07_Pancreas.tar\",\n",
        "    \"Task08_HepaticVessel\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task08_HepaticVessel.tar\",\n",
        "    \"Task09_Spleen\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task09_Spleen.tar\",\n",
        "    \"Task10_Colon\": \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task10_Colon.tar\"\n",
        "}\n",
        "md5 = {\n",
        "    \"Task01_BrainTumour\": \"240a19d752f0d9e9101544901065d872\",\n",
        "    \"Task02_Heart\": \"06ee59366e1e5124267b774dbd654057\",\n",
        "    \"Task03_Liver\": \"a90ec6c4aa7f6a3d087205e23d4e6397\",\n",
        "    \"Task04_Hippocampus\": \"9d24dba78a72977dbd1d2e110310f31b\",\n",
        "    \"Task05_Prostate\": \"35138f08b1efaef89d7424d2bcc928db\",\n",
        "    \"Task06_Lung\": \"8afd997733c7fc0432f71255ba4e52dc\",\n",
        "    \"Task07_Pancreas\": \"4f7080cfca169fa8066d17ce6eb061e4\",\n",
        "    \"Task08_HepaticVessel\": \"641d79e80ec66453921d997fbf12a29c\",\n",
        "    \"Task09_Spleen\": \"410d4a301da4e5b2f6f86ec3ddba524e\",\n",
        "    \"Task10_Colon\": \"bad7a188931dc2f6acf72b08eb6202d0\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Sm88xxD1BXW2"
      },
      "outputs": [],
      "source": [
        "def data(task):  \n",
        "    \n",
        "    \n",
        "    res = resource[task]\n",
        "    resVal = md5[task]\n",
        "\n",
        "    taskTar = task + \".tar\"\n",
        "    compressed_file = os.path.join(root_dir, taskTar)\n",
        "    data_dir = os.path.join(root_dir, task)\n",
        "    if not os.path.exists(data_dir):\n",
        "        download_and_extract(res, compressed_file, root_dir, resVal)\n",
        "\n",
        "    train_images = sorted(\n",
        "        glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "    train_labels = sorted(\n",
        "        glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "    data_dicts = [\n",
        "        {\"image\": image_name, \"label\": label_name}\n",
        "        for image_name, label_name in zip(train_images, train_labels)\n",
        "    ]\n",
        "    valSplit = len(data_dicts)//5\n",
        "    train_files, val_files = data_dicts[:-valSplit], data_dicts[-valSplit:]\n",
        "\n",
        "    return train_files, val_files\n",
        "\n",
        "tf, vf = data(task)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_YpWqISBXW3",
        "outputId": "63d27338-5588-4200-e6a5-99565ba58ec0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "208 52\n",
            "max: 2467.62744140625, min: 0.0, \n",
            "torch.Size([38, 47, 37])\n",
            "torch.Size([35, 51, 40])\n",
            "torch.Size([36, 49, 41])\n",
            "torch.Size([36, 54, 27])\n",
            "torch.Size([38, 54, 30])\n",
            "torch.Size([34, 53, 32])\n",
            "torch.Size([35, 55, 33])\n",
            "torch.Size([35, 52, 33])\n",
            "torch.Size([35, 52, 33])\n",
            "torch.Size([33, 46, 38])\n",
            "torch.Size([34, 47, 36])\n",
            "torch.Size([32, 47, 41])\n",
            "torch.Size([34, 47, 43])\n",
            "torch.Size([33, 44, 41])\n",
            "torch.Size([37, 43, 43])\n",
            "torch.Size([35, 46, 38])\n",
            "torch.Size([34, 48, 35])\n",
            "torch.Size([32, 45, 38])\n",
            "torch.Size([32, 49, 30])\n",
            "torch.Size([34, 50, 34])\n",
            "torch.Size([35, 49, 34])\n",
            "torch.Size([35, 51, 35])\n",
            "torch.Size([38, 51, 35])\n",
            "torch.Size([32, 51, 31])\n",
            "torch.Size([36, 50, 32])\n",
            "torch.Size([33, 47, 38])\n",
            "torch.Size([36, 51, 37])\n",
            "torch.Size([35, 50, 34])\n",
            "torch.Size([35, 49, 35])\n",
            "torch.Size([34, 49, 37])\n",
            "torch.Size([36, 50, 33])\n",
            "torch.Size([38, 52, 35])\n",
            "torch.Size([37, 47, 34])\n",
            "torch.Size([36, 57, 37])\n",
            "torch.Size([38, 55, 40])\n",
            "torch.Size([35, 50, 36])\n",
            "torch.Size([36, 50, 34])\n",
            "torch.Size([34, 49, 35])\n",
            "torch.Size([38, 48, 39])\n",
            "torch.Size([32, 54, 34])\n",
            "torch.Size([35, 55, 37])\n",
            "torch.Size([35, 52, 34])\n",
            "torch.Size([35, 46, 42])\n",
            "torch.Size([33, 49, 37])\n",
            "torch.Size([33, 55, 29])\n",
            "torch.Size([35, 48, 40])\n",
            "torch.Size([37, 45, 40])\n",
            "torch.Size([33, 51, 32])\n",
            "torch.Size([34, 49, 32])\n",
            "torch.Size([38, 51, 33])\n",
            "torch.Size([36, 51, 31])\n",
            "torch.Size([36, 52, 32])\n"
          ]
        }
      ],
      "source": [
        "print(len(tf), len(vf))\n",
        "check_ds = Dataset(data=vf, transform=Compose([LoadImaged(keys=[\"image\", \"label\"]),EnsureChannelFirstd(keys=[\"image\", \"label\"]),CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),EnsureTyped(keys=[\"image\", \"label\"])]))\n",
        "check_loader = DataLoader(check_ds, batch_size=1)\n",
        "check_data = first(check_loader)\n",
        "check_data[\"image\"][0][0].shape, check_data[\"label\"][0][0].shape\n",
        "\n",
        "img,lab = check_data[\"image\"][0][0], check_data[\"label\"][0][0]\n",
        "\n",
        "min = torch.min(img)\n",
        "max = torch.max(img)\n",
        "\n",
        "print(f\"max: {max}, min: {min}, \")\n",
        "for d in check_loader:\n",
        "    print(d[\"image\"][0][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "eLv0bsPABXW3"
      },
      "outputs": [],
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=0, a_max=2460,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        #RandAffined(\n",
        "        #    keys=['image', 'label'],\n",
        "        #    mode=('bilinear', 'nearest'),\n",
        "        #    prob=1.0, spatial_size=(16,16,16),\n",
        "        #    rotate_range=(0, 0, np.pi/15),\n",
        "        #    scale_range=(0.1, 0.1, 0.1)),\n",
        "        Resized(keys=[\"image\", \"label\"], spatial_size=(32,32,32)),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=(\"bilinear\", \"nearest\")),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=0, a_max=2460,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\"),\n",
        "        Resized(keys=[\"image\", \"label\"], spatial_size=(32,32,32)),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "dPf8ybAIBXW4",
        "outputId": "044e0c36-fbcf-4389-fa34-ed43baea2ce1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: torch.Size([32, 32, 32]), label shape: torch.Size([32, 32, 32])\n",
            "image max intensity: 0.047256097197532654\n",
            "image min intensity: 0.0018292681779712439\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "check_ds = Dataset(data=tf, transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=1)\n",
        "check_data = first(check_loader)\n",
        "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
        "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
        "\n",
        "min = torch.min(image)\n",
        "max = torch.max(image)\n",
        "print(f\"image max intensity: {max}\")\n",
        "print(f\"image min intensity: {min}\")\n",
        "plt.figure(\"check\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(image[:, :, 10], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, 10])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_ds = Dataset(data=vf, transform=val_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=1)\n",
        "check_data = first(check_loader)\n",
        "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
        "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
        "\n",
        "min = torch.min(image)\n",
        "max = torch.max(image)\n",
        "print(f\"image max intensity: {max}\")\n",
        "print(f\"image min intensity: {min}\")\n",
        "print(label.dtype)\n",
        "print(type(label))\n",
        "plt.figure(\"check\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(image[:, :, 10], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, 10])\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "ppmuaygeTMYg",
        "outputId": "a7fb690b-1928-4e2a-b348-71b5328ff209"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "image shape: torch.Size([32, 32, 32]), label shape: torch.Size([32, 32, 32])\n",
            "image max intensity: 0.6232317686080933\n",
            "image min intensity: 1.536090113942611e-17\n",
            "torch.float32\n",
            "<class 'torch.Tensor'>\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "   batch = list(filter(lambda x: x is not None, batch))\n",
        "   return torch.utils.data.dataloader.default_collate(batch)   "
      ],
      "metadata": {
        "id": "JeaI4Cuiv4MV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s-DaHsqqBXW4"
      },
      "outputs": [],
      "source": [
        "# train_ds = CacheDataset(\n",
        "#     data=tf, transform=train_transforms, cache_rate=1.0, num_workers=2)\n",
        "\n",
        "# train_loader = DataLoader(train_ds, batch_size=2, shuffle=False, num_workers=2)\n",
        "\n",
        "# val_ds = CacheDataset(\n",
        "#     data=vf, transform=val_transforms, cache_rate=1.0, num_workers=2)\n",
        "\n",
        "# val_loader = DataLoader(val_ds, batch_size=1, num_workers=2)\n",
        "##normal dataloader no cache\n",
        "\n",
        "train_ds = Dataset(data=tf, transform=train_transforms)\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
        "\n",
        "val_ds = Dataset(data=vf, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in val_loader:\n",
        "    i = d['image'][0][0].shape\n",
        "    l = d['label'][0][0].shape\n",
        "\n",
        "    print(f\"val label dims: {d['label'][0][0].shape}\")\n",
        "    print(f\"val image dims: {d['image'][0][0].shape}\")\n",
        "    if(i != l):\n",
        "      print(\"\\t im a hoe\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8YfCDKBGnlx5",
        "outputId": "fb66e06c-5150-40b2-c05b-59fac97556c1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n",
            "val label dims: torch.Size([32, 32, 32])\n",
            "val image dims: torch.Size([32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for d in train_loader:\n",
        "    i = d['image'][0][0].shape\n",
        "    l = d['label'][0][0].shape\n",
        "\n",
        "    print(f\"train label dims: {d['label'][0][0].shape}\")\n",
        "    print(f\"train image dims: {d['image'][0][0].shape}\")\n",
        "    if(i != l):\n",
        "      print(\"\\t im a hoe\")\n",
        "\n"
      ],
      "metadata": {
        "id": "QTeDaZbZnJEF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c222715a-6200-4d48-e232-a0244a12708d"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n",
            "train label dims: torch.Size([32, 32, 32])\n",
            "train image dims: torch.Size([32, 32, 32])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cur = train_ds[0-1][\"image\"]\n",
        "next = train_ds[0][\"image\"]\n",
        "cur.shae"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmvO6fj38TnR",
        "outputId": "ac65208f-7259-44cf-e39a-61c808ab1cf6"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 32, 32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "RQOXOLGpBXW4"
      },
      "outputs": [],
      "source": [
        "# standard PyTorch program style: create UNet, DiceLoss and Adam optimizer\n",
        "device = torch.device(\"cuda:0\")\n",
        "model = UNet(\n",
        "    spatial_dims=3,\n",
        "    in_channels=1,\n",
        "    out_channels=3,\n",
        "    channels=(16, 32, 64, 128, 256),\n",
        "    strides=(2, 2, 2, 2),\n",
        "    num_res_units=2,\n",
        "    norm=Norm.BATCH,\n",
        "    dropout=0.2\n",
        ").to(device)\n",
        "loss_function = DiceLoss(to_onehot_y=True, softmax=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F5CSEQzGBXW5",
        "outputId": "ab1e3383-41e7-4f5b-90e3-9c7fbb1e11fb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------\n",
            "epoch 1/300\n",
            "10/208, train_loss: 0.4025\n",
            "20/208, train_loss: 0.4211\n",
            "30/208, train_loss: 0.4263\n",
            "40/208, train_loss: 0.4380\n",
            "50/208, train_loss: 0.4428\n",
            "60/208, train_loss: 0.4595\n",
            "70/208, train_loss: 0.3664\n",
            "80/208, train_loss: 0.3658\n",
            "90/208, train_loss: 0.4275\n",
            "100/208, train_loss: 0.3627\n",
            "110/208, train_loss: 0.4290\n",
            "120/208, train_loss: 0.4106\n",
            "130/208, train_loss: 0.3814\n",
            "140/208, train_loss: 0.4632\n",
            "150/208, train_loss: 0.3902\n",
            "160/208, train_loss: 0.3960\n",
            "170/208, train_loss: 0.3541\n",
            "180/208, train_loss: 0.3421\n",
            "190/208, train_loss: 0.4040\n",
            "200/208, train_loss: 0.3646\n",
            "epoch 1 average loss: 0.3873\n",
            "----------\n",
            "epoch 2/300\n",
            "10/208, train_loss: 0.3289\n",
            "20/208, train_loss: 0.3351\n",
            "30/208, train_loss: 0.3056\n",
            "40/208, train_loss: 0.3200\n",
            "50/208, train_loss: 0.3451\n",
            "60/208, train_loss: 0.2625\n",
            "70/208, train_loss: 0.3331\n",
            "80/208, train_loss: 0.3208\n",
            "90/208, train_loss: 0.2810\n",
            "100/208, train_loss: 0.3093\n",
            "110/208, train_loss: 0.3030\n",
            "120/208, train_loss: 0.3350\n",
            "130/208, train_loss: 0.3615\n",
            "140/208, train_loss: 0.2820\n",
            "150/208, train_loss: 0.3895\n",
            "160/208, train_loss: 0.3017\n",
            "170/208, train_loss: 0.3161\n",
            "180/208, train_loss: 0.2732\n",
            "190/208, train_loss: 0.2981\n",
            "200/208, train_loss: 0.2502\n",
            "epoch 2 average loss: 0.3211\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "<class 'torch.Tensor'>\n",
            "val inputs: torch.Size([1, 1, 32, 32, 32])\n",
            "val labels: torch.Size([1, 1, 32, 32, 32])\n",
            "saved new best metric model\n",
            "current epoch: 2 current mean dice: 0.0016\n",
            "best mean dice: 0.0016 at epoch: 2\n",
            "----------\n",
            "epoch 3/300\n",
            "10/208, train_loss: 0.2899\n",
            "20/208, train_loss: 0.3215\n",
            "30/208, train_loss: 0.2367\n",
            "40/208, train_loss: 0.3848\n",
            "50/208, train_loss: 0.2597\n",
            "60/208, train_loss: 0.2553\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-69fab5ae8fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mstep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         inputs, labels = (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    528\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 530\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    531\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    532\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1206\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1207\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1208\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1171\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1172\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1173\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1174\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1175\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# unserialize the data after having released the lock\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/multiprocessing/reductions.py\u001b[0m in \u001b[0;36mrebuild_storage_fd\u001b[0;34m(cls, df, size)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrebuild_storage_fd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m     \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mdetach\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0;34m'''Get the fd.  This should only be called once.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0m_resource_sharer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/multiprocessing/resource_sharer.py\u001b[0m in \u001b[0;36mget_connection\u001b[0;34m(ident)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mident\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;34m'''Return connection from which to receive identified resource.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mident\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maddress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/importlib/_bootstrap.py\u001b[0m in \u001b[0;36mparent\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "max_epochs = 300\n",
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=3)])\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=3)])\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        #cur = train_ds[step-1][\"image\"]\n",
        "        #next = train_ds[step][\"image\"]\n",
        "        #print(f\"Current img shape: {cur.shape}, next img shape: {next.shape}\")\n",
        "        #print(f\"train inputs: {inputs.shape}\")\n",
        "        #print(f\"train labels: {labels.shape}\")\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        if step % 10 == 0:\n",
        "          print(\n",
        "              f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "              f\"train_loss: {loss.item():.4f}\")\n",
        "          \n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                print(type(val_inputs))\n",
        "                print(f\"val inputs: {val_inputs.shape}\")\n",
        "                print(f\"val labels: {val_labels.shape}\")\n",
        "                roi_size = (16,16,16)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(\n",
        "                    val_inputs, roi_size, sw_batch_size, model)\n",
        "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
        "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
        "                # compute metric for current iteration\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            # reset the status for next validation round\n",
        "            dice_metric.reset()\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eV_FrdJFW4Z_"
      },
      "outputs": [],
      "source": [
        "#further training\n",
        "\n",
        "PATH = '/content/task/best_metric_model.pth'\n",
        "\n",
        "ckp = torch.load(PATH)\n",
        "model.load_state_dict(ckp)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr =0.00001)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaDTDpB6VnMj"
      },
      "outputs": [],
      "source": [
        "\n",
        "max_epochs = 300\n",
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "metric_values = []\n",
        "post_pred = Compose([EnsureType(), AsDiscrete(argmax=True, to_onehot=2)])\n",
        "post_label = Compose([EnsureType(), AsDiscrete(to_onehot=2)])\n",
        "\n",
        "for epoch in range(max_epochs):\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch + 1}/{max_epochs}\")\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch_data in train_loader:\n",
        "        step += 1\n",
        "        inputs, labels = (\n",
        "            batch_data[\"image\"].to(device),\n",
        "            batch_data[\"label\"].to(device),\n",
        "        )\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs.float())\n",
        "        loss = loss_function(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "            f\"train_loss: {loss.item():.4f}\")\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch + 1} average loss: {epoch_loss:.4f}\")\n",
        "\n",
        "    if (epoch + 1) % val_interval == 0:\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].to(device),\n",
        "                    val_data[\"label\"].to(device),\n",
        "                )\n",
        "                roi_size = (160, 160, 160)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(\n",
        "                    val_inputs, roi_size, sw_batch_size, model)\n",
        "                val_outputs = [post_pred(i) for i in decollate_batch(val_outputs)]\n",
        "                val_labels = [post_label(i) for i in decollate_batch(val_labels)]\n",
        "                # compute metric for current iteration\n",
        "                dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = dice_metric.aggregate().item()\n",
        "            # reset the status for next validation round\n",
        "            dice_metric.reset()\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GXE6GH5xCeSM"
      },
      "outputs": [],
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zeou6ZoTCfuk"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load(\n",
        "    os.path.join(root_dir, \"/content/task/Task02_Heart/best_metric_model_heart.pth\")))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(val_loader):\n",
        "        roi_size = (160, 160, 160)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(\n",
        "            val_data[\"image\"].to(device), roi_size, sw_batch_size, model\n",
        "        )\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 40], cmap=\"gray\")\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(val_data[\"label\"][0, 0, :, :, 40])\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(torch.argmax(\n",
        "            val_outputs, dim=1).detach().cpu()[0, :, :, 40])\n",
        "        plt.show()\n",
        "        if i == 2:\n",
        "            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yf3emisJChN0"
      },
      "outputs": [],
      "source": [
        "val_org_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Orientationd(keys=[\"image\"], axcodes=\"RAS\"),\n",
        "        Spacingd(keys=[\"image\"], pixdim=(\n",
        "            1.5, 1.5, 2.0), mode=\"bilinear\"),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=0, a_max=1610,\n",
        "            b_min=0.0, b_max=1.0, clip=True,\n",
        "        ),\n",
        "        EnsureTyped(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")\n",
        "\n",
        "val_org_ds = Dataset(\n",
        "    data=vf, transform=val_org_transforms)\n",
        "val_org_loader = DataLoader(val_org_ds, batch_size=1, num_workers=4)\n",
        "\n",
        "post_transforms = Compose([\n",
        "    EnsureTyped(keys=\"pred\"),\n",
        "    Invertd(\n",
        "        keys=\"pred\",\n",
        "        transform=val_org_transforms,\n",
        "        orig_keys=\"image\",\n",
        "        meta_keys=\"pred_meta_dict\",\n",
        "        orig_meta_keys=\"image_meta_dict\",\n",
        "        meta_key_postfix=\"meta_dict\",\n",
        "        nearest_interp=False,\n",
        "        to_tensor=True,\n",
        "    ),\n",
        "    AsDiscreted(keys=\"pred\", argmax=True, to_onehot=2),\n",
        "    AsDiscreted(keys=\"label\", to_onehot=2),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-IbkIzgCihB"
      },
      "outputs": [],
      "source": [
        "model.load_state_dict(torch.load('/content/task/Task02_Heart/best_metric_model_heart.pth'))\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for val_data in val_org_loader:\n",
        "        val_inputs = val_data[\"image\"].to(device)\n",
        "        roi_size = (48,48,48)\n",
        "        sw_batch_size = 4\n",
        "        val_data[\"pred\"] = sliding_window_inference(\n",
        "            val_inputs, roi_size, sw_batch_size, model)\n",
        "        val_data = [post_transforms(i) for i in decollate_batch(val_data)]\n",
        "        val_outputs, val_labels = from_engine([\"pred\", \"label\"])(val_data)\n",
        "        # compute metric for current iteration\n",
        "        dice_metric(y_pred=val_outputs, y=val_labels)\n",
        "\n",
        "    # aggregate the final mean dice result\n",
        "    metric_org = dice_metric.aggregate().item()\n",
        "    # reset the status for next validation round\n",
        "    dice_metric.reset()\n",
        "\n",
        "print(\"Metric on original image spacing: \", metric_org)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zthvUXU1aJY0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Task04_Hippocampus.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "6a57817e21ccdb11dbbd137a893031cffe177059cb194ad2f5ed401c62986600"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('cdnn')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}